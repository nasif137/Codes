{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231a7c65",
   "metadata": {},
   "source": [
    "The outline of the project is as follows:\n",
    "1. Import the required libraries.\n",
    "2. Download the historical stock prices using Yahoo Finance API.\n",
    "3. Calculate the daily returns of each stock and the market.\n",
    "4. Compute the mean daily return and covariance matrix.\n",
    "5. Define the mean-variance optimization function and solve for the optimal portfolio weights.\n",
    "6. Print the results.\n",
    "7. Calculate the Sharpe ratio\n",
    "8. Solve for and print volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747bf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5aa15c",
   "metadata": {},
   "source": [
    "We use the Pandas library to create an empty DataFrame object called df. We then loop over each ticker symbol in the tickers list (JNJ, PG, PFE, and SPY) and download the adjusted close prices for that symbol using the get_data_yahoo() method from the Pandas DataReader (pdr) library. The start and end dates of the historical data to download are specified by start_date and end_date.\n",
    "\n",
    "The downloaded data is then assigned to a new column in the DataFrame df with the same name as the ticker symbol. This creates a DataFrame with 4 columns, one for each ticker symbol, and rows containing the daily adjusted close prices of each stock between the start and end dates.\n",
    "\n",
    "Overall, this code downloads historical stock price data for a specific date range for multiple companies and stores it in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2be36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['JNJ', 'PG', 'PFE']\n",
    "start_date = '2020-03-01'\n",
    "end_date = '2022-03-01'\n",
    "df = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    data = pdr.get_data_yahoo(ticker, start_date, end_date)['Adj Close']\n",
    "    df[ticker] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2cfa7",
   "metadata": {},
   "source": [
    "We calculate the daily percentage change in the adjusted close prices of multiple stocks and stores the result in a new DataFrame called returns. The pct_change() method computes the percentage change between the current and a prior element in a DataFrame, and dropna() method removes any resulting missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73ce8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9a3b6",
   "metadata": {},
   "source": [
    "Now, we compute the mean daily return and the covariance matrix of the daily returns for the stocks in the returns DataFrame calculated in the previous step. The mean() method computes the mean daily return for each stock, and the cov() method computes the covariance matrix of the daily returns for all stocks. The resulting mu and Sigma variables are used in Step 5 to optimize the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992d42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = returns.mean()\n",
    "Sigma = returns.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecefd5",
   "metadata": {},
   "source": [
    "We define a Python function called mean_variance_optimization that calculates the optimal portfolio weights that minimize portfolio risk for a given expected return, based on the mean daily returns and covariance matrix of multiple stocks. It uses linear algebra operations to calculate the optimal weights, which are returned as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab0ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_variance_optimization(mu, Sigma):\n",
    "    n = len(mu)\n",
    "    A = np.ones(n)\n",
    "    b = 1\n",
    "    C = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            C[i, j] = 2 * Sigma.iloc[i, j]\n",
    "    w = np.linalg.inv(C) @ A / (A.T @ np.linalg.inv(C) @ A)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb37c3",
   "metadata": {},
   "source": [
    "Now, we solve for the optimal portfolio weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6000d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = mean_variance_optimization(mu, Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e4659",
   "metadata": {},
   "source": [
    "Now, we print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0e4acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Portfolio Weights:\n",
      " [0.48870062 0.37878346 0.13251592]\n",
      "Expected Daily Return: 0.0007\n",
      "Portfolio Variance: 0.0002\n",
      "\n",
      "Covariance Matrix:\n",
      "          JNJ        PG       PFE\n",
      "JNJ  0.000224  0.000175  0.000179\n",
      "PG   0.000175  0.000247  0.000157\n",
      "PFE  0.000179  0.000157  0.000396\n"
     ]
    }
   ],
   "source": [
    "print('Optimal Portfolio Weights:\\n', w)\n",
    "print('Expected Daily Return:', round(w @ mu, 4))\n",
    "print('Portfolio Variance:', round(w @ Sigma @ w.T, 4))\n",
    "print('\\nCovariance Matrix:')\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd64803",
   "metadata": {},
   "source": [
    "The results show the optimal portfolio weights, expected daily return, and portfolio variance calculated using the mean-variance optimization function. The optimal portfolio weights represent the fraction of the total investment to allocate to each stock in the portfolio.\n",
    "\n",
    "In this case, the optimal portfolio weights suggest investing 33.8% of the portfolio in Johnson & Johnson, 25.9% in Procter & Gamble, 10.3% in Pfizer, and 29.9% in SPDR S&P 500 ETF Trust. The expected daily return of the portfolio is 0.0007 or 0.07%, and the portfolio variance is 0.0002 or 0.02%.\n",
    "\n",
    "These results indicate that the portfolio is expected to generate a small daily return with relatively low risk. However, it's important to note that these results are based on historical data and may not necessarily predict future performance. Therefore, investors should exercise caution and perform their own due diligence before making any investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac6508",
   "metadata": {},
   "source": [
    "Now, we print the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4caff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance Matrix:\n",
      "          JNJ        PG       PFE\n",
      "JNJ  0.000224  0.000175  0.000179\n",
      "PG   0.000175  0.000247  0.000157\n",
      "PFE  0.000179  0.000157  0.000396\n"
     ]
    }
   ],
   "source": [
    "print('\\nCovariance Matrix:')\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c795e9d",
   "metadata": {},
   "source": [
    "The results show the covariance matrix of the daily returns for the four stocks included in the analysis (Johnson & Johnson, Procter & Gamble, Pfizer, and SPDR S&P 500 ETF Trust). The covariance matrix measures the degree to which the returns of the stocks move together over time.\n",
    "\n",
    "In this case, the diagonal elements of the covariance matrix represent the variances of the individual stocks, while the off-diagonal elements represent the covariances between pairs of stocks. The results suggest that all the stocks have positive covariances, meaning that they tend to move in the same direction. However, the magnitude of the covariances varies, with some pairs of stocks having stronger correlations than others.\n",
    "\n",
    "For example, the covariance between Johnson & Johnson and Procter & Gamble is 0.000175, while the covariance between Pfizer and SPDR S&P 500 ETF Trust is 0.000152. These results can be useful in identifying diversification opportunities and constructing optimal portfolios that balance risk and return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7b723",
   "metadata": {},
   "source": [
    "Next, we calculate and print the Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5788cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sharpe Ratio: 0.0483\n"
     ]
    }
   ],
   "source": [
    "risk_free_rate = 0.0\n",
    "expected_return = w @ mu\n",
    "portfolio_volatility = np.sqrt(w @ Sigma @ w.T)\n",
    "sharpe_ratio = (expected_return - risk_free_rate) / portfolio_volatility\n",
    "print('\\nSharpe Ratio:', round(sharpe_ratio, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c9b74",
   "metadata": {},
   "source": [
    "The Sharpe ratio of 0.0544 suggests that the portfolio has generated a relatively small excess return per unit of risk taken. While positive, the Sharpe ratio is not particularly high, indicating that the portfolio may not be generating sufficient returns to justify the level of risk taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1796d75",
   "metadata": {},
   "source": [
    "Lastly, we generate the portfolio volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c44a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Volatility: 0.0141\n"
     ]
    }
   ],
   "source": [
    "print('Portfolio Volatility:', round(portfolio_volatility, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df37728",
   "metadata": {},
   "source": [
    "The portfolio volatility of 0.0137 suggests that the portfolio's returns have been relatively stable over time.\n",
    "\n",
    "Now, we store the Tau values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171519e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_values = [0.2, 0.5, 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9f112",
   "metadata": {},
   "source": [
    "We are defining a variable called \"views\" which is a list of tuples, where each tuple contains a Pandas DataFrame, a Pandas Series, and a Numpy array. These tuples represent different views of the same data. Each view has its own set of weights, which are stored in a Numpy array called \"omega_values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42ebe817",
   "metadata": {},
   "outputs": [],
   "source": [
    "views = [(pd.DataFrame([[1, 0, 0], [0, 1, 0]], index=['View 1', 'View 2'], columns=['A', 'B', 'C']), \n",
    "          pd.Series([0.015, 0.04], index=['View 1', 'View 2']), np.array([0.5, 0.5])),\n",
    "         (pd.DataFrame([[0, 1, -1]], index=['View 3'], columns=['A', 'B', 'C']), \n",
    "          pd.Series([0.005], index=['View 3']), np.array([0.7])),\n",
    "         (pd.DataFrame([[0, 1, 0]], index=['View 4'], columns=['A', 'B', 'C']), \n",
    "          pd.Series([0.02], index=['View 4']), np.array([0.3]))]\n",
    "omega_values = [0.3, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b66d5e",
   "metadata": {},
   "source": [
    "We are calculating the market equilibrium portfolio weights for each value of tau by first computing the inverse of the covariance matrix Sigma plus tau times the identity matrix. Then, we multiply this inverse by the expected returns vector mu to obtain mu_tilde. Finally, we calculate the market equilibrium portfolio weights pi by dividing mu_tilde by tau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ddbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tau in tau_values:\n",
    "    sigma_tilde = np.linalg.inv(np.linalg.inv(Sigma) + tau*np.eye(Sigma.shape[0]))\n",
    "    mu_tilde = np.dot(sigma_tilde,mu)\n",
    "    pi = mu_tilde / tau "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf29174",
   "metadata": {},
   "source": [
    "Now, we calculate the Black-Litterman optimal portfolio for each view and omega value. We start by initializing an empty list called table_data. We then loop through each view and its corresponding omega value, and calculate the posterior sigma and posterior mu. Using these values and the market equilibrium portfolio weights, we use the minimize function to optimize the Black-Litterman weights, subject to the constraint that the sum of weights is equal to 1. We then append the tau value, omega value, and the resulting Black-Litterman weights to the table_data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f54b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = []\n",
    "for i, (P, Q, omega) in enumerate(views):\n",
    "    omega = np.diag(np.repeat(omega_values[i], P.shape[0]))\n",
    "    tau_sigma = tau * Sigma\n",
    "    posterior_sigma = np.linalg.inv(np.linalg.inv(tau_sigma) + np.dot(np.dot(np.transpose(P), np.linalg.inv(omega)), P))\n",
    "    posterior_mu = np.dot(posterior_sigma, (np.dot(np.dot(np.transpose(P), np.linalg.inv(omega)), Q) + np.dot(np.linalg.inv(tau_sigma), pi)))\n",
    "    bl_weights = minimize(lambda w: np.dot(np.dot(w.T, posterior_sigma), w), x0=np.random.rand(mu.shape[0]), \n",
    "                              constraints=[{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}], bounds=[(0,1) for i in range(mu.shape[0])])['x']\n",
    "    table_data.append([tau_values[i], omega_values[i], bl_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa66c2",
   "metadata": {},
   "source": [
    "We are printing the table of Black-Litterman optimal portfolio weights for each view and omega value. We create a table with columns 'tau', 'omega', and 'weights[JNJ][PG][PFE]'. We then populate the table with the data stored in 'table_data' and print the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "685626ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tau  omega                              weights[JNJ][PG][PFE]\n",
      "0  0.2    0.3  [0.07943659713369094, 0.5992855480232255, 0.32...\n",
      "1  0.5    0.5  [0.5487967046947977, 2.7755575615628914e-17, 0...\n",
      "2  0.8    0.7  [0.32983172534847516, 0.10638420506253515, 0.5...\n"
     ]
    }
   ],
   "source": [
    "table_columns = ['tau', 'omega', 'weights[JNJ][PG][PFE]']\n",
    "df = pd.DataFrame(table_data, columns=table_columns)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
